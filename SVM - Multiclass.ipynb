{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn.metrics as metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First put all features in one pandas.DataFrame and add image ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all csv files needed\n",
    "df = pd.read_csv('features_all_malte.csv')\n",
    "df2 = pd.read_csv('features_all_fabian.csv')\n",
    "ids = pd.read_csv('image_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids.drop(['lesion_id', 'dx', 'dx_type', 'age', 'sex', 'localization'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add image ids to df2 (features_all_fabian.csv)\n",
    "merge_df = df2.join(ids, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = merge_df.set_index('image_id').join(df.set_index('image_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort here already! Needed for export later\n",
    "df = df.sort_values(by = 'image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('features_all_together.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up and drop all rows where NAs occur\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['validation'] == 0]\n",
    "df_test = df[df['validation'] == 1]\n",
    "\n",
    "# create label DataFrames\n",
    "y_train = pd.DataFrame(df_train['dx'])\n",
    "y_test = pd.DataFrame(df_test['dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature DataFrames\n",
    "X_train = df_train.drop(['dx', 'validation', 'malignant'], axis = 1)\n",
    "\n",
    "X_test = df_test.drop(['dx', 'validation', 'malignant'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    }
   ],
   "source": [
    "#scaling each feature to [0,1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train = pd.DataFrame(min_max_scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(min_max_scaler.fit_transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection #1\n",
    "from sklearn.feature_selection import SelectKBest,f_classif, chi2,mutual_info_classif\n",
    "\n",
    "select = SelectKBest(f_classif , k=26)\n",
    "select.fit(X_train, np.ravel(y_train))\n",
    "names = X_train.columns.values[select.get_support(indices=True)]\n",
    "X_train = pd.DataFrame(select.transform(X_train))\n",
    "X_test = pd.DataFrame(select.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection #2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "select = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=25)) #random_state to make reproducable\n",
    "select.fit(X_train, np.ravel(y_train))\n",
    "names = X_train.columns.values[select.get_support(indices=True)]\n",
    "X_train = pd.DataFrame(select.transform(X_train))\n",
    "X_test = pd.DataFrame(select.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection #3\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#the smaller C the fewer features selected.\n",
    "lsvc = LinearSVC(C=0.1, penalty=\"l1\", dual=False).fit(X_train, np.ravel(y_train))\n",
    "select = SelectFromModel(lsvc)\n",
    "select.fit(X_train, np.ravel(y_train))\n",
    "names = X_train.columns.values[select.get_support(indices=True)]\n",
    "X_train = pd.DataFrame(select.transform(X_train))\n",
    "X_test = pd.DataFrame(select.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Moment_R_L01', 'Moment_R_L02', 'Moment_R_L20', 'Moment_G_L20',\n",
       "       'Moment_B_L02', 'Moment_B_L20', 'average_red3', 'average_green3',\n",
       "       'average_blue3', 'area_variance01', 'area_variance02',\n",
       "       'area_variance03', 'area_variance1', 'area_variance2',\n",
       "       'area_variance3', 'average_blue2', 'average_green2',\n",
       "       'average_red2', 'contrast2', 'correlation2', 'dissimilarity2',\n",
       "       'energy2', 'nu12', 'perimeter'], dtype=object)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing.scale(X_train)\n",
    "X_test  = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf', C=3, gamma = 'auto', probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probabilities = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabs = pd.DataFrame(prediction_probabilities)\n",
    "probabs.columns = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "predictions = probabs.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  36   15   11    0    4   18    0]\n",
      " [  14   46   13    0    5   51    0]\n",
      " [  12   11   97    0   40  114    1]\n",
      " [   5    6    6    3    1    9    0]\n",
      " [   9    1   17    0   92  160    1]\n",
      " [   6   11   54    2   86 1518    0]\n",
      " [   0    1    5    0    4   14   12]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test,predictions)\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if overfitting the data by looking at training dataset\n",
    "\n",
    "#prediction_probabilities = model.predict_proba(X_train)\n",
    "#probabs = pd.DataFrame(prediction_probabilities)\n",
    "#probabs.columns = [False, True]\n",
    "#predictions = probabs.idxmax(axis=1)\n",
    "#confusion = confusion_matrix(y_train,predictions)\n",
    "#print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification metrics (https://stackoverflow.com/a/43331484/8614827)\n",
    "FP = confusion.sum(axis=0) - np.diag(confusion)  \n",
    "FN = confusion.sum(axis=1) - np.diag(confusion)\n",
    "TP = np.diag(confusion)\n",
    "TN = confusion.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9195539625647152\n",
      "0.4007114922729541\n",
      "0.9159333617525623\n",
      "0.4458782247005443\n"
     ]
    }
   ],
   "source": [
    "# metrics used on MTEC website\n",
    "print(ACC.mean()) #accuracy\n",
    "print(TPR.mean()) #sensitivity\n",
    "print(TNR.mean()) #specificity\n",
    "print(metrics.f1_score(y_test, predictions, average=None).mean()) #F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing and csv Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(prediction_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns = ['AKIEC','BCC','BKL','DF','MEL','NV','VASC']\n",
    "result = result[['MEL','NV','BCC','AKIEC','BKL','DF','VASC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>BCC</th>\n",
       "      <th>AKIEC</th>\n",
       "      <th>BKL</th>\n",
       "      <th>DF</th>\n",
       "      <th>VASC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032456</td>\n",
       "      <td>0.142599</td>\n",
       "      <td>0.085633</td>\n",
       "      <td>0.071311</td>\n",
       "      <td>0.473621</td>\n",
       "      <td>0.190362</td>\n",
       "      <td>0.004017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.797608</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035165</td>\n",
       "      <td>0.312280</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>0.300031</td>\n",
       "      <td>0.223395</td>\n",
       "      <td>0.004936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140106</td>\n",
       "      <td>0.437406</td>\n",
       "      <td>0.070157</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.312745</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.014877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.968515</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MEL        NV       BCC     AKIEC       BKL        DF      VASC\n",
       "0  0.032456  0.142599  0.085633  0.071311  0.473621  0.190362  0.004017\n",
       "1  0.150560  0.797608  0.004534  0.001266  0.042992  0.000951  0.002089\n",
       "2  0.035165  0.312280  0.101272  0.022920  0.300031  0.223395  0.004936\n",
       "3  0.140106  0.437406  0.070157  0.014706  0.312745  0.010002  0.014877\n",
       "4  0.009591  0.968515  0.003097  0.002228  0.011212  0.004529  0.000827"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label = pd.DataFrame(df_test.index)\n",
    "image_label = image_label.sort_values(by = 'image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label= image_label.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv = image_label.join(result, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv.columns = ['image','MEL','NV','BCC','AKIEC','BKL','DF','VASC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv.to_csv('multiclass_classification', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>BCC</th>\n",
       "      <th>AKIEC</th>\n",
       "      <th>BKL</th>\n",
       "      <th>DF</th>\n",
       "      <th>VASC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0024312</td>\n",
       "      <td>0.032456</td>\n",
       "      <td>0.142599</td>\n",
       "      <td>0.085633</td>\n",
       "      <td>0.071311</td>\n",
       "      <td>0.473621</td>\n",
       "      <td>0.190362</td>\n",
       "      <td>0.004017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0024317</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.797608</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0024318</td>\n",
       "      <td>0.035165</td>\n",
       "      <td>0.312280</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>0.300031</td>\n",
       "      <td>0.223395</td>\n",
       "      <td>0.004936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0024324</td>\n",
       "      <td>0.140106</td>\n",
       "      <td>0.437406</td>\n",
       "      <td>0.070157</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.312745</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.014877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024328</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.968515</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image       MEL        NV       BCC     AKIEC       BKL        DF  \\\n",
       "0  ISIC_0024312  0.032456  0.142599  0.085633  0.071311  0.473621  0.190362   \n",
       "1  ISIC_0024317  0.150560  0.797608  0.004534  0.001266  0.042992  0.000951   \n",
       "2  ISIC_0024318  0.035165  0.312280  0.101272  0.022920  0.300031  0.223395   \n",
       "3  ISIC_0024324  0.140106  0.437406  0.070157  0.014706  0.312745  0.010002   \n",
       "4  ISIC_0024328  0.009591  0.968515  0.003097  0.002228  0.011212  0.004529   \n",
       "\n",
       "       VASC  \n",
       "0  0.004017  \n",
       "1  0.002089  \n",
       "2  0.004936  \n",
       "3  0.014877  \n",
       "4  0.000827  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probabilities = rfc.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
